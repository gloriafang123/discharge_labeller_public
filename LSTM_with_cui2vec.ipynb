{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "LSTM_with_cui2vec.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "F61k7hpCnn4d"
      },
      "source": [
        "# LSTM UPDATES\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "d8zBymRAn4ag",
        "colab": {}
      },
      "source": [
        "from keras.preprocessing import sequence\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Embedding, LSTM, Bidirectional"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EqCP86q5oRG9",
        "colab_type": "text"
      },
      "source": [
        "## Glove setup"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "e376bcf8-8065-4e71-c1fc-2e4bdd99d04f",
        "id": "KaNHiqVFnn1V",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        }
      },
      "source": [
        "!wget http://nlp.stanford.edu/data/glove.6B.zip\n",
        "!unzip glove*.zip"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-05-11 18:43:54--  http://nlp.stanford.edu/data/glove.6B.zip\n",
            "Resolving nlp.stanford.edu (nlp.stanford.edu)... 171.64.67.140\n",
            "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:80... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://nlp.stanford.edu/data/glove.6B.zip [following]\n",
            "--2020-05-11 18:43:54--  https://nlp.stanford.edu/data/glove.6B.zip\n",
            "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:443... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: http://downloads.cs.stanford.edu/nlp/data/glove.6B.zip [following]\n",
            "--2020-05-11 18:43:54--  http://downloads.cs.stanford.edu/nlp/data/glove.6B.zip\n",
            "Resolving downloads.cs.stanford.edu (downloads.cs.stanford.edu)... 171.64.64.22\n",
            "Connecting to downloads.cs.stanford.edu (downloads.cs.stanford.edu)|171.64.64.22|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 862182613 (822M) [application/zip]\n",
            "Saving to: ‘glove.6B.zip.1’\n",
            "\n",
            "glove.6B.zip.1      100%[===================>] 822.24M  2.20MB/s    in 6m 27s  \n",
            "\n",
            "2020-05-11 18:50:21 (2.12 MB/s) - ‘glove.6B.zip.1’ saved [862182613/862182613]\n",
            "\n",
            "Archive:  glove.6B.zip\n",
            "replace glove.6B.50d.txt? [y]es, [n]o, [A]ll, [N]one, [r]ename: "
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X3rHPLxpaadB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "2ecc3a21-33be-4214-d2b5-f26c3993b823"
      },
      "source": [
        "!wget https://ndownloader.figshare.com/files/10959626?private_link=00d69861786cd0156d81 -O cui2vec.zip\n",
        "###need to rename zip\n",
        "!unzip cui*.zip"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  cui2vec.zip\n",
            "  inflating: cui2vec_pretrained.csv  \n",
            "   creating: __MACOSX/\n",
            "  inflating: __MACOSX/._cui2vec_pretrained.csv  \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "JSLU6bnOnn1C",
        "colab": {}
      },
      "source": [
        "with open('glove.6B.300d.txt', 'r') as f: \n",
        "    first_row = f.read().split('\\n')[8]\n",
        "\n",
        "import numpy as np\n",
        "word_embeddings = {}\n",
        "f = open('glove.6B.300d.txt', encoding='utf-8')\n",
        "for line in f:\n",
        "    values = line.split()\n",
        "    word = values[0]\n",
        "    coefs = np.asarray(values[1:], dtype='float32')\n",
        "    word_embeddings[word] = coefs\n",
        "f.close()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "mG3CzWp-nn2j",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "li = []\n",
        "import glob\n",
        "all_files = list(glob.glob(\"*_cui.csv\"))\n",
        "for filename in all_files:\n",
        "    df = pd.read_csv(filename)\n",
        "    li.append(df)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "D7W0NPaQnn0a",
        "colab": {}
      },
      "source": [
        "# turn a label to a vector\n",
        "def label_vec(string):\n",
        "  labels = [\"Other\",\"Movement\",\"Meds_Treatments\",\"Procedures_Results\",\n",
        "            \"Vitals_Labs\",\"Symptoms_Signs\", \"ProcedureHistory\",\"MedicationHistory\",\n",
        "            \"DiagnosisHistory\",\"Demographics\"]\n",
        "  vec = np.zeros(len(labels))\n",
        "\n",
        "  if string in labels:\n",
        "    idx = labels.index(string)\n",
        "    vec[idx] = 1\n",
        "  return vec"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "e4LWN7Fcnn0O",
        "colab": {}
      },
      "source": [
        "# turn a vector to a label\n",
        "def vec_label(vec):\n",
        "  idx = np.argmax(vec)\n",
        "  labels = [\"Other\",\"Movement\",\"Meds_Treatments\",\"Procedures_Results\",\n",
        "            \"Vitals_Labs\",\"Symptoms_Signs\", \"ProcedureHistory\",\"MedicationHistory\",\n",
        "            \"DiagnosisHistory\",\"Demographics\"]\n",
        "  return labels[idx] if idx  < len(labels) else \"Other\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "VfpljEdennzL",
        "colab": {}
      },
      "source": [
        "max_length= max([len(s) for s in li])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z4nEJ6yFXIKn",
        "colab_type": "text"
      },
      "source": [
        "# MODEL USING MASKING AND JUST CUI2VEC\n",
        "Acc on new data: ~0.64\n",
        "Can just directly run the block below"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pOAZh1VZc_HX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(len(word_embeddings[\"is\"]))\n",
        "print(len(word_embeddings[\"that\"]))\n",
        "import numpy as np\n",
        "cui_embeddings = {}\n",
        "f = open('cui2vec_pretrained.csv', encoding='utf-8')\n",
        "for line in f:\n",
        "    values = line.split(',')\n",
        "    cui = values[0]\n",
        "    if len(cui) > 2:\n",
        "      cui = cui[1:-1]\n",
        "      if cui[0] != \"C\":\n",
        "        continue\n",
        "      vector = values[1:]\n",
        "      if len(vector) != 500:\n",
        "        raise Exception\n",
        "      ##### length 500\n",
        "      coefs = np.asarray(vector, dtype='float32')\n",
        "      cui_embeddings[cui] = coefs\n",
        "f.close()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cAgxMlm8XQMr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.utils import Sequence\n",
        "import math\n",
        "class medicalData(Sequence):\n",
        "\n",
        "    def __init__(self, x_set, y_set, batch_size=1):\n",
        "        self.x, self.y = x_set, y_set\n",
        "        self.batch_size = batch_size\n",
        "\n",
        "    def __len__(self):\n",
        "        return math.ceil(len(self.x) / self.batch_size)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        retX = self.x[idx]\n",
        "        retY = self.y[idx]\n",
        "\n",
        "        return np.array(retX), np.array(retY)\n",
        "\n",
        "def get_words_labels_from_df(df, max_length=len(df)):\n",
        "  labels = np.concatenate([df['labels'][0:max_length],\n",
        "                             ['Other']*(max_length - len(df['labels']))\n",
        "                             ], axis=0)\n",
        "  \n",
        "  cuis = np.concatenate([df['cui'][0:max_length],\n",
        "                             [' ']*(max_length - len(df['cui']))\n",
        "                             ], axis=0) \n",
        "  words = np.concatenate([df['tokens'][0:max_length],\n",
        "                             [' ']*(max_length - len(df['tokens']))\n",
        "                             ], axis=0) \n",
        "\n",
        "  \n",
        "  words_vec = [cui_embeddings.get(cuis[i], np.zeros(500)) for i in range(len(words))]\n",
        "  \n",
        "  labels_vec = [label_vec(l) for l in labels]\n",
        "\n",
        "  words_vec2 = np.array(words_vec).reshape(1, len(words_vec), len(words_vec[0]))\n",
        "  labels_vec2 = np.array(labels_vec).reshape(1, len(labels_vec), len(labels_vec[0]))\n",
        "\n",
        "  return words_vec2, labels_vec2\n",
        "\n",
        "\n",
        "def eval():\n",
        "  final_avg = 0\n",
        "  filtered_avg = 0\n",
        "  total =0\n",
        "  correct= 0\n",
        "  print(\"NOW EVALUATING......\")\n",
        "  num_test= 100\n",
        "  for i in range(num_test):\n",
        "    preds = model.predict(np.reshape(w_batches[-1*i], [1] + list(w_batches[-1*i].shape)),\n",
        "                          batch_size=1) \n",
        "\n",
        "    # print([vec_label(j) for j in preds[0]])\n",
        "    # print([vec_label(j) for j in l_batches[-1*i]])\n",
        "    predicted_labels = np.array([vec_label(j) for ind, j in enumerate(preds[0])])\n",
        "    actual_labels = np.array([vec_label(j) for ind, j in enumerate(l_batches[-1*i])])\n",
        "\n",
        "    final_avg += np.sum(actual_labels== predicted_labels)/(len(actual_labels))\n",
        "\n",
        "\n",
        "    for j in range(len(li[-1*i]['cui'])):\n",
        "      if li[-1*i][\"cui\"][j] in cui_embeddings:\n",
        "        total += 1\n",
        "        if actual_labels[j] == predicted_labels[j]:\n",
        "          correct+=1\n",
        "\n",
        "  filtered_avg = correct/total\n",
        "  print(\"Average of Everything: \", final_avg/num_test)\n",
        "  print(\"Average predicted CUI Terms correct\", filtered_avg)\n",
        "  model.save('masking_justcui_25ep')\n",
        "\n",
        "w_batches = None\n",
        "l_batches = None\n",
        "for df in li:\n",
        "  wv, lv = get_words_labels_from_df(df, max_length)\n",
        "  # concatenate word vec, label vec...\n",
        "  if w_batches is None:\n",
        "    w_batches = wv\n",
        "  else:\n",
        "    w_batches = np.concatenate([w_batches, wv], axis=0)\n",
        "  # w_batches.append(wv)\n",
        "  if l_batches is None:\n",
        "    l_batches = lv\n",
        "  else:\n",
        "    l_batches = np.concatenate([l_batches, lv], axis=0)\n",
        "  # l_batches.append(lv)\n",
        "w_batches = np.asarray(w_batches)\n",
        "l_batches = np.asarray(l_batches)\n",
        "print(w_batches.shape, l_batches.shape)\n",
        "\n",
        "\n",
        "\n",
        "from keras.layers import Masking\n",
        "\n",
        "special_value = np.zeros(500)\n",
        "model = Sequential()\n",
        "model.add(Masking(mask_value=special_value, input_shape=(None, 500)))\n",
        "model.add(Bidirectional(LSTM(50, return_sequences=True)))\n",
        "model.add(Dense(10, activation='softmax'))\n",
        "\n",
        "model.compile(optimizer='rmsprop',\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "ds = medicalData(w_batches, l_batches)\n",
        "print(np.array(w_batches).shape)\n",
        "print(np.array(l_batches).shape)\n",
        "model.summary(90)\n",
        "for i in range(50):\n",
        "  print(\"epoch \", i)\n",
        "  model.fit(w_batches[:-100], l_batches[:-100], batch_size=4, epochs=1)\n",
        "  eval()\n",
        "\n",
        "# from keras import models\n",
        "# model = models.load_model('masking_justcui_25ep')\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v-17JqkuQTpU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "10002a7c-e7ea-4792-c297-624af0a4c224"
      },
      "source": [
        "print(final_avg/100)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.13329140461215938\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DP7p_NYghyKt",
        "colab_type": "text"
      },
      "source": [
        "#Model with Masking and cui2vec+Glove\n",
        "used glove 300d and padded the extra 200 values with 0s\n",
        "\n",
        "Acc of ~.68 "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yehguscrh3QJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.utils import Sequence\n",
        "import math\n",
        "class medicalData(Sequence):\n",
        "\n",
        "    def __init__(self, x_set, y_set, batch_size=1):\n",
        "        self.x, self.y = x_set, y_set\n",
        "        self.batch_size = batch_size\n",
        "\n",
        "    def __len__(self):\n",
        "        return math.ceil(len(self.x) / self.batch_size)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        retX = self.x[idx]\n",
        "        retY = self.y[idx]\n",
        "\n",
        "        return np.array(retX), np.array(retY)\n",
        "\n",
        "def get_words_labels_from_df(df, max_length=len(df)):\n",
        "  labels = np.concatenate([df['labels'][0:max_length],\n",
        "                             ['Other']*(max_length - len(df['labels']))\n",
        "                             ], axis=0)\n",
        "  \n",
        "  cuis = np.concatenate([df['cui'][0:max_length],\n",
        "                             [' ']*(max_length - len(df['cui']))\n",
        "                             ], axis=0) \n",
        "  words = np.concatenate([df['tokens'][0:max_length],\n",
        "                             [' ']*(max_length - len(df['tokens']))\n",
        "                             ], axis=0) \n",
        "\n",
        "  \n",
        "  cuis_vec = [cui_embeddings.get(cuis[i], np.zeros(500)) for i in range(len(words))]\n",
        "  tokens_vec = [word_embeddings.get(words[i], np.zeros(300)) for i in range(len(words))]\n",
        "  words_vec = [np.concatenate([cuis_vec[i], tokens_vec[i]]) for i in range(len(words))]\n",
        "  labels_vec = [label_vec(l) for l in labels]\n",
        "\n",
        "  words_vec2 = np.array(words_vec).reshape(1, len(words_vec), len(words_vec[0]))\n",
        "  labels_vec2 = np.array(labels_vec).reshape(1, len(labels_vec), len(labels_vec[0]))\n",
        "\n",
        "  return words_vec2, labels_vec2\n",
        "\n",
        "def eval():\n",
        "  final_avg = 0\n",
        "  filtered_avg = 0\n",
        "  total =0\n",
        "  correct= 0\n",
        "  print(\"NOW EVALUATING......\")\n",
        "  num_test= 100\n",
        "  for i in range(num_test):\n",
        "    preds = model.predict(np.reshape(w_batches[-1*i], [1] + list(w_batches[-1*i].shape)),\n",
        "                          batch_size=1) \n",
        "\n",
        "    # print([vec_label(j) for j in preds[0]])\n",
        "    # print([vec_label(j) for j in l_batches[-1*i]])\n",
        "    predicted_labels = np.array([vec_label(j) for ind, j in enumerate(preds[0])])\n",
        "    actual_labels = np.array([vec_label(j) for ind, j in enumerate(l_batches[-1*i])])\n",
        "\n",
        "    final_avg += np.sum(actual_labels== predicted_labels)/(len(actual_labels))\n",
        "\n",
        "\n",
        "    for j in range(len(li[-1*i]['cui'])):\n",
        "      if li[-1*i][\"cui\"][j] in cui_embeddings:\n",
        "        total += 1\n",
        "        if actual_labels[j] == predicted_labels[j]:\n",
        "          correct+=1\n",
        "\n",
        "  filtered_avg = correct/total\n",
        "  print(\"Average of Everything: \", final_avg/num_test)\n",
        "  print(\"Average predicted CUI Terms correct\", filtered_avg)\n",
        "  model.save('masking_glovecui_25ep')\n",
        "\n",
        "\n",
        "w_batches = None\n",
        "l_batches = None\n",
        "for df in li:\n",
        "  wv, lv = get_words_labels_from_df(df, max_length)\n",
        "  # concatenate word vec, label vec...\n",
        "  if w_batches is None:\n",
        "    w_batches = wv\n",
        "  else:\n",
        "    w_batches = np.concatenate([w_batches, wv], axis=0)\n",
        "  # w_batches.append(wv)\n",
        "  if l_batches is None:\n",
        "    l_batches = lv\n",
        "  else:\n",
        "    l_batches = np.concatenate([l_batches, lv], axis=0)\n",
        "  # l_batches.append(lv)\n",
        "w_batches = np.asarray(w_batches)\n",
        "l_batches = np.asarray(l_batches)\n",
        "print(w_batches.shape, l_batches.shape)\n",
        "\n",
        "\n",
        "\n",
        "from keras.layers import Masking\n",
        "\n",
        "special_value = np.zeros(800)\n",
        "model = Sequential()\n",
        "model.add(Masking(mask_value=special_value, input_shape=(None, 800)))\n",
        "model.add(Bidirectional(LSTM(50, return_sequences=True)))\n",
        "model.add(Dense(10, activation='softmax'))\n",
        "\n",
        "model.compile(optimizer='rmsprop',\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "ds = medicalData(w_batches, l_batches)\n",
        "print(np.array(w_batches).shape)\n",
        "print(np.array(l_batches).shape)\n",
        "model.summary(90)\n",
        "for i in range(50):\n",
        "  print(\"epoch \", i)\n",
        "  model.fit(w_batches[:-100], l_batches[:-100], batch_size=4, epochs=1)\n",
        "  eval()\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EcpomMsHXUEk",
        "colab_type": "text"
      },
      "source": [
        "# Model with Variable-length inputs\n",
        "can just directly run the code block below\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GWeil0z5Xae9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_words_labels_from_df(df, max_length=len(df)):\n",
        "  labels = df['labels']\n",
        "  \n",
        "  cuis = df['cui']\n",
        "  words = df['tokens']\n",
        "  \n",
        "  cuis_vec = [cui_embeddings.get(cuis[i], np.zeros(500)) for i in range(len(words))]\n",
        "  tokens_vec = [word_embeddings.get(words[i], np.zeros(300)) for i in range(len(words))]\n",
        "  words_vec = [np.concatenate([cuis_vec[i], tokens_vec[i]]) for i in range(len(words))]\n",
        "  labels_vec = [label_vec(l) for l in labels]\n",
        "\n",
        "  words_vec2 = np.array(words_vec).reshape(1, len(words_vec), len(words_vec[0]))\n",
        "  labels_vec2 = np.array(labels_vec).reshape(1, len(labels_vec), len(labels_vec[0]))\n",
        "\n",
        "  return words_vec2, labels_vec2\n",
        "\n",
        "def eval():\n",
        "  final_avg = 0\n",
        "  filtered_avg = 0\n",
        "  total =0\n",
        "  correct= 0\n",
        "  print(\"NOW EVALUATING......\")\n",
        "  num_test= 100\n",
        "  for i in range(num_test):\n",
        "    preds = model.predict(np.reshape(w_batches[-1*i], [1] + list(w_batches[-1*i].shape)),\n",
        "                          batch_size=1) \n",
        "\n",
        "    # print([vec_label(j) for j in preds[0]])\n",
        "    # print([vec_label(j) for j in l_batches[-1*i]])\n",
        "    predicted_labels = np.array([vec_label(j) for ind, j in enumerate(preds[0])])\n",
        "    actual_labels = np.array([vec_label(j) for ind, j in enumerate(l_batches[-1*i])])\n",
        "\n",
        "    final_avg += np.sum(actual_labels== predicted_labels)/(len(actual_labels))\n",
        "\n",
        "\n",
        "    for j in range(len(li[-1*i]['cui'])):\n",
        "      if li[-1*i][\"cui\"][j] in cui_embeddings:\n",
        "        total += 1\n",
        "        if actual_labels[j] == predicted_labels[j]:\n",
        "          correct+=1\n",
        "\n",
        "  filtered_avg = correct/total\n",
        "  print(\"Average of Everything: \", final_avg/num_test)\n",
        "  print(\"Average predicted CUI Terms correct\", filtered_avg)\n",
        "  # model.save('varinp_glovecui_25ep')\n",
        "\n",
        "variable_w = []\n",
        "variable_l = []\n",
        "for df in li:\n",
        "  wv, lv = get_words_labels_from_df(df, max_length)\n",
        "  # concatenate word vec, label vec...\n",
        "  variable_w.append(wv)\n",
        "  variable_l.append(lv)\n",
        "\n",
        "\n",
        "\n",
        "from keras.models import Sequential\n",
        "from keras.layers import LSTM, Dense, TimeDistributed\n",
        "from keras.utils import to_categorical\n",
        "import numpy as np\n",
        "\n",
        "model = Sequential()\n",
        "\n",
        "model.add(LSTM(50, return_sequences=True, input_shape=(None, 800)))\n",
        "model.add(Dense(10, activation='softmax'))\n",
        "\n",
        "print(model.summary(90))\n",
        "\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "def train_generator(variable_w, variable_l):\n",
        "    i=0\n",
        "    length = len(variable_w)\n",
        "    while True:\n",
        "        x_train, y_train = np.array(variable_w[i % length]), np.array(variable_l[i % length])\n",
        "        i+= 1\n",
        "        yield x_train, y_train\n",
        "\n",
        "for _ in range(50):\n",
        "  print(\"epoch \", _)\n",
        "  model.fit_generator(train_generator(variable_w[:-100], variable_l[:-100]), steps_per_epoch=len(variable_w)-1, epochs=1, verbose=1)\n",
        "  eval()\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GvSlGJLIDHF5",
        "colab_type": "text"
      },
      "source": [
        "# Model with Just Glove"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1vcHS4Wc8D_S",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.utils import Sequence\n",
        "import math\n",
        "class medicalData(Sequence):\n",
        "\n",
        "    def __init__(self, x_set, y_set, batch_size=1):\n",
        "        self.x, self.y = x_set, y_set\n",
        "        self.batch_size = batch_size\n",
        "\n",
        "    def __len__(self):\n",
        "        return math.ceil(len(self.x) / self.batch_size)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        retX = self.x[idx]\n",
        "        retY = self.y[idx]\n",
        "\n",
        "        return np.array(retX), np.array(retY)\n",
        "\n",
        "def get_words_labels_from_df(df, max_length=len(df)):\n",
        "  labels = np.concatenate([df['labels'][0:max_length],\n",
        "                             ['Other']*(max_length - len(df['labels']))\n",
        "                             ], axis=0)\n",
        "  \n",
        "  cuis = np.concatenate([df['cui'][0:max_length],\n",
        "                             [' ']*(max_length - len(df['cui']))\n",
        "                             ], axis=0) \n",
        "  words = np.concatenate([df['tokens'][0:max_length],\n",
        "                             [' ']*(max_length - len(df['tokens']))\n",
        "                             ], axis=0) \n",
        "\n",
        "  \n",
        "  words_vec = [word_embeddings.get(words[i], np.zeros(500)) for i in range(len(words))]\n",
        "  \n",
        "  labels_vec = [label_vec(l) for l in labels]\n",
        "\n",
        "  words_vec2 = np.array(words_vec).reshape(1, len(words_vec), len(words_vec[0]))\n",
        "  labels_vec2 = np.array(labels_vec).reshape(1, len(labels_vec), len(labels_vec[0]))\n",
        "\n",
        "  return words_vec2, labels_vec2\n",
        "\n",
        "\n",
        "def eval():\n",
        "  final_avg = 0\n",
        "  filtered_avg = 0\n",
        "  total =0\n",
        "  correct= 0\n",
        "  print(\"NOW EVALUATING......\")\n",
        "  num_test= 100\n",
        "  for i in range(num_test):\n",
        "    preds = model.predict(np.reshape(w_batches[-1*i], [1] + list(w_batches[-1*i].shape)),\n",
        "                          batch_size=1) \n",
        "\n",
        "    # print([vec_label(j) for j in preds[0]])\n",
        "    # print([vec_label(j) for j in l_batches[-1*i]])\n",
        "    predicted_labels = np.array([vec_label(j) for ind, j in enumerate(preds[0])])\n",
        "    actual_labels = np.array([vec_label(j) for ind, j in enumerate(l_batches[-1*i])])\n",
        "\n",
        "    final_avg += np.sum(actual_labels== predicted_labels)/(len(actual_labels))\n",
        "\n",
        "\n",
        "    for j in range(len(li[-1*i]['cui'])):\n",
        "      if li[-1*i][\"cui\"][j] in cui_embeddings:\n",
        "        total += 1\n",
        "        if actual_labels[j] == predicted_labels[j]:\n",
        "          correct+=1\n",
        "\n",
        "  filtered_avg = correct/total\n",
        "  print(\"Average of Everything: \", final_avg/num_test)\n",
        "  print(\"Average predicted CUI Terms correct\", filtered_avg)\n",
        "  model.save('masking_justglove_25ep')\n",
        "\n",
        "# w_batches = None\n",
        "# l_batches = None\n",
        "# for df in li:\n",
        "#   wv, lv = get_words_labels_from_df(df, max_length)\n",
        "#   # concatenate word vec, label vec...\n",
        "#   if w_batches is None:\n",
        "#     w_batches = wv\n",
        "#   else:\n",
        "#     w_batches = np.concatenate([w_batches, wv], axis=0)\n",
        "#   # w_batches.append(wv)\n",
        "#   if l_batches is None:\n",
        "#     l_batches = lv\n",
        "#   else:\n",
        "#     l_batches = np.concatenate([l_batches, lv], axis=0)\n",
        "#   # l_batches.append(lv)\n",
        "# w_batches = np.asarray(w_batches)\n",
        "# l_batches = np.asarray(l_batches)\n",
        "# print(w_batches.shape, l_batches.shape)\n",
        "\n",
        "\n",
        "\n",
        "from keras.layers import Masking\n",
        "\n",
        "special_value = np.zeros(500)\n",
        "model = Sequential()\n",
        "model.add(Masking(mask_value=special_value, input_shape=(None, 500)))\n",
        "model.add(Bidirectional(LSTM(50, return_sequences=True)))\n",
        "model.add(Dense(10, activation='softmax'))\n",
        "\n",
        "model.compile(optimizer='rmsprop',\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "ds = medicalData(w_batches, l_batches)\n",
        "print(np.array(w_batches).shape)\n",
        "print(np.array(l_batches).shape)\n",
        "model.summary(90)\n",
        "for i in range(50):\n",
        "  print(\"epoch \", i)\n",
        "  model.fit(w_batches[:-100], l_batches[:-100], batch_size=4, epochs=1)\n",
        "  eval()\n",
        "\n",
        "# from keras import models\n",
        "# model = models.load_model('masking_justcui_25ep')"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}